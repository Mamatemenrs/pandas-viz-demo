{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Local module for downloading data sets\n",
    "from bin.download import get_CalIt2_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to download data\n",
    "get_CalIt2_data('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Time Series in Pandas Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/CalIt2+Building+People+Counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Raw Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('data/CalIt2.data', header=None, names=['Flow', 'Date', 'Time', 'Count']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    df = pd.read_csv(filepath, header=None, names=['Flow', 'Date', 'Time', 'Count'])\n",
    "    \n",
    "    # Process times\n",
    "    df['Timestamp'] = df['Date'] + ' ' + df['Time']\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "    \n",
    "    df['Date'] = df['Timestamp'].dt.date.astype('datetime64')\n",
    "    df['Time'] = df['Timestamp'].dt.time\n",
    "    \n",
    "    \n",
    "    # Process Flow Column\n",
    "    df.loc[df['Flow']==7, 'Flow'] = 'Out'\n",
    "    df.loc[df['Flow']==9, 'Flow'] = 'In'\n",
    "    \n",
    "    df = df.set_index('Timestamp')\n",
    "    return df\n",
    "    \n",
    "\n",
    "df = load_data('data/CalIt2.data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index()['Timestamp'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot to get separate columns for Inflow and Outflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pivot_data(df):\n",
    "    \n",
    "    df_pivot = df.pivot_table(index='Timestamp', columns=['Flow'])\n",
    "    df_pivot.columns = ['In', 'Out']\n",
    "    \n",
    "    df_pivot['Net'] = df_pivot['In'] - df_pivot['Out']\n",
    "    \n",
    "    df_pivot = df_pivot.reset_index()\n",
    "    \n",
    "    df_pivot['Date'] = df_pivot['Timestamp'].dt.date.astype('datetime64')\n",
    "    df_pivot['Time'] = df_pivot['Timestamp'].dt.time\n",
    "    df_pivot['Month'] = df_pivot['Date'].dt.month\n",
    "    df_pivot['Day'] = df_pivot['Date'].dt.dayofweek\n",
    "    \n",
    "    df_pivot = df_pivot.set_index('Timestamp')\n",
    "    \n",
    "    return df_pivot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot = pivot_data(df)\n",
    "df_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative flow throughout day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_cumulative(df_pivot):\n",
    "\n",
    "    cumulative = (df_pivot\n",
    "      .groupby('Date')\n",
    "      .agg({\n",
    "          'In':'cumsum',\n",
    "          'Out':'cumsum',\n",
    "          'Net':'cumsum'\n",
    "      }))\n",
    "    \n",
    "    cumulative.columns = ['In_cumulative', 'Out_cumulative', 'Net_cumulative']\n",
    "    return cumulative\n",
    "\n",
    "cumulative = daily_cumulative(df_pivot)\n",
    "\n",
    "def cumulative_features(df):\n",
    "    cumulative = daily_cumulative(df)\n",
    "    return df.join(cumulative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = cumulative_features(df_pivot)\n",
    "joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(joined\n",
    "  .loc['2005-10-31', 'Net_cumulative']\n",
    "  .plot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_pivot(df_pivot, sampling='h'):\n",
    "    \n",
    "    return (df_pivot\n",
    "            .resample(sampling)\n",
    "            .agg({'In':'sum',\n",
    "                  'Out': 'sum',\n",
    "                  'Net':'sum',\n",
    "                  'Date': 'last',\n",
    "                  'Time': 'first'}))\n",
    "\n",
    "\n",
    "df_hourly = resample_pivot(df_pivot, 'h')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourly_with_confidence_bars():\n",
    "    df_hourly = resample_pivot(df_pivot)\n",
    "    df_g = (df_hourly\n",
    "     .groupby('Time')\n",
    "     .agg({'In':['mean', 'std']}))\n",
    "\n",
    "    df_g.columns = df_g.columns.get_level_values(1)\n",
    "\n",
    "\n",
    "    ax = df_g.plot(y='mean')\n",
    "\n",
    "    ax.fill_between(df_g.index, \n",
    "                    df_g['mean']+df_g['std'],\n",
    "                    df_g['mean']-df_g['std'],\n",
    "                    alpha=0.3)\n",
    "\n",
    "hourly_with_confidence_bars()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Day of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily = resample_pivot(df_pivot, 'd')\n",
    "df_weekdays = df_daily[df_daily['Date'].dt.dayofweek < 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to events data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv('data/CalIt2.events', header=None)\n",
    "events.columns = ['Timestamp', 'start_time', 'end_time', 'event_type']\n",
    "events['event_type'] = events['event_type'].apply(lambda x: int(x[0]))\n",
    "\n",
    "events['start_time'] = pd.to_datetime(events['Timestamp'] + ' ' + events['start_time'])\n",
    "events['end_time'] = pd.to_datetime(events['Timestamp'] + ' ' + events['end_time'])\n",
    "events['Timestamp'] = pd.to_datetime(events['Timestamp'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events['start_time'].dt.time.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events['length'] = events['end_time'] - events['start_time']\n",
    "events['length'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join to flow data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = df['Date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inflow = df[df['Flow'] == 'In']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hour_before = (df_inflow['Count']\n",
    "                   .rolling(window=2, closed='left')\n",
    "                   .sum())\n",
    "\n",
    "all_hour_before.name='hour_before'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events['start_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inflow_window = df_inflow.merge(all_hour_before, left_index=True, right_index=True)\n",
    "df_inflow_window = (df_inflow_window.reset_index()\n",
    "                     .merge(events[['start_time', 'event_type']],\n",
    "                            left_on='Timestamp',\n",
    "                            right_on='start_time',\n",
    "                            how='left'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inflow_window[df_inflow_window['Timestamp'] == '2005-07-26 11:00:00']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inflow_window.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_inflow_window.fillna(0)\n",
    " .groupby(['Time', 'event_type'])['hour_before']\n",
    " .mean()\n",
    " .to_frame())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Careful!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_before_pivot = (df_inflow_window.fillna(0)\n",
    "                     .groupby(['Time', 'event_type'])['hour_before']\n",
    "                     .mean()\n",
    "                     .to_frame()\n",
    "                     .reset_index()\n",
    "                     .pivot(index='Time', columns='event_type'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_before_pivot.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_before_pivot.dropna(subset=[('hour_before', 1.0),('hour_before', 2.0),('hour_before', 3.0)],\n",
    "                         how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weekdays['In'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot['Day'] = df_pivot['Date'].dt.dayofweek\n",
    "df_dayofweek_mean = df_pivot.groupby(['Day', 'Time']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['Day'] = df_daily['Date'].dt.dayofweek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_all = df_pivot.reset_index().groupby(['Month', 'Time']).agg({\n",
    "    'In':'mean',\n",
    "    'Out':'mean',\n",
    "    'Net':'mean'\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sparklines and small multiples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_month(month_ind):\n",
    "    months = {\n",
    "    7:'July',\n",
    "    8:'August',\n",
    "    9:'September',\n",
    "    10:'October',\n",
    "    11:'November'}\n",
    "    \n",
    "    return months[month_ind]\n",
    "\n",
    "\n",
    "def get_day_of_week(dayofweek_ind):\n",
    "    days = {\n",
    "        0:'Monday',\n",
    "        1:'Tuesday',\n",
    "        2:'Wednesday',\n",
    "        3:'Thursday',\n",
    "        4:'Friday',\n",
    "        5:'Saturday',\n",
    "        6:'Sunday'}\n",
    "    \n",
    "    return days[dayofweek_ind]\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_sparkline(df, by='Month', col='In'):\n",
    "    \n",
    "\n",
    "    #fig, ax = plt.subplots(1,1,figsize=(4,.5));\n",
    "\n",
    "    ax = df[[col]].plot(legend=None, figsize=(4,.5));\n",
    "\n",
    "    month = get_month(df['Month'][0])\n",
    "\n",
    "\n",
    "    # remove all the axes\n",
    "    for k,v in ax.spines.items():\n",
    "        v.set_visible(False)\n",
    "    if month != 'November':\n",
    "        plt.xlabel('')\n",
    "\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    #plt.axis('off')\n",
    "    plt.xlabel('')\n",
    "\n",
    "    plt.ylabel(month, rotation='horizontal', labelpad=0, size=10)\n",
    "    ax.yaxis.set_label_coords(1.1, 0)\n",
    "    \n",
    "    return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sparkline(df, col='In', by='Day'):\n",
    "   \n",
    "    \n",
    "    fig, ax = plt.subplots(1,1,figsize=(4,.5))\n",
    "\n",
    "    df.plot(y=col, ax=ax, legend=None)\n",
    "\n",
    "    ylabel = ''\n",
    "    if by == 'Day':\n",
    "        ylabel = get_day_of_week(df.reset_index()['Day'][0])\n",
    "    if by == 'Month':\n",
    "        ylabel = get_month(df['Month'][0])\n",
    "        \n",
    "    \n",
    "\n",
    "    # remove all the axes\n",
    "    for k,v in ax.spines.items():\n",
    "        v.set_visible(False)\n",
    "        \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    #plt.axis('off')\n",
    "    plt.xlabel('', rotation='horizontal', labelpad=0, size=10)\n",
    "\n",
    "    plt.ylabel(ylabel, rotation='horizontal', labelpad=0, size=10)\n",
    "    ax.yaxis.set_label_coords(1.1, 0)\n",
    "    # remove legend\n",
    "    \n",
    "    \n",
    "def sparklines(df, col='In', by='Day'):\n",
    "    \n",
    "    df.groupby(by).apply(lambda x: sparkline(x, col, by))\n",
    "    \n",
    "sparklines(df_dayofweek_mean)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparklines(monthly_all, col='In', by='Month')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
